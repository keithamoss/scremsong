[supervisord]
nodaemon=true
logfile=/app/logs/scremsong_supervisord.log
loglevel=info


# [program:uwsgi]
# command=/usr/sbin/uwsgi --ini /app/uwsgi.ini
# # command=/usr/sbin/uwsgi --ini /app/uwsgi.ini --need-app --plugin python3
# autostart=true
# autorestart=true
# stdout_logfile=/app/logs/uwsgi.log
# stdout_logfile_maxbytes=0
# redirect_stderr=true


[program:scremsong_asgi]
# Config sourced from the official Django-Channels docs for Daphne
# https://channels.readthedocs.io/en/stable/deploying.html#nginx-supervisor-ubuntu
# Modified to only run a single process (for simplicity of the ops work)

# Directory where your site's project files are located
directory=/app

# `--access-log -` writes to stdout
command=daphne scremsong.asgi:application --port 8000 -b 0.0.0.0 --access-log - --proxy-headers

# Number of processes to startup, roughly the number of CPUs you have
numprocs=1

# Give each process a unique name so they can be told apart
# Not relevant when we're only running one process, but left in
process_name=scremsong_asgi%(process_num)d

# Automatically start and recover processes
autostart=true
autorestart=true
# How long it needs to be up for to be considered "running"
startsecs=5

# Choose where you want your log to go
stdout_logfile=/app/logs/scremsong_app_asgi.log
redirect_stderr=true


[program:scremsong_asgi_workers]
# Bits of this sourced from https://medium.com/@saurabhpresent/deploying-django-channels-using-supervisor-and-ngnix-2f9a25393eef

command=python /app/manage.py runworker channels

# Number of processes to startup, roughly the number of CPUs you have
numprocs=2

# Give each process a unique name so they can be told apart
process_name=scremsong_asgi_worker%(process_num)s

# Automatically start and recover processes
autostart=true
autorestart=true
# How long it needs to be up for to be considered "running"
startsecs=5

; Need to wait for currently executing tasks to finish at shutdown.
; Increase this if you have very long running tasks.
stopwaitsecs=10

; Causes supervisor to send the termination signal (SIGTERM) to the whole process group.
stopasgroup=true

# Choose where you want your log to go
stdout_logfile = /app/logs/scremsong_channels_asgi_workers.log
redirect_stderr=True


[program:scremsong_python_rq]
; Point the command to the specific rq command you want to run.
; If you use virtualenv, be sure to point it to
; /path/to/virtualenv/bin/rq
; Also, you probably want to include a settings module to configure this
; worker.  For more info on that, see http://python-rq.org/docs/workers/
command=python manage.py rqworker --with-scheduler high default low
; process_num is required if you specify >1 numprocs
process_name=%(program_name)s-%(process_num)s

; If you want to run more than one worker instance, increase this
# 1 for streaming, 1 for Twitter rate limit collection, 1 for tweet backfill + processing tweets, and 1 for solely processing tweets
numprocs=6

; This is the directory from which RQ is ran. Be sure to point this to the
; directory where your source code is importable from
directory=/app

; RQ requires the TERM signal to perform a warm shutdown. If RQ does not die
; within 10 seconds, supervisor will forcefully kill it
stopsignal=TERM

; These are up to you
autostart=true
autorestart=true

# How long it needs to be up for to be considered "running"
startsecs=5

# Choose where you want your log to go
stdout_logfile=/app/logs/scremsong_python_rq_workers.log
redirect_stderr=True